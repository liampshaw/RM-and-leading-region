
```{r}
library(ggplot2)
library(knitr)
library(xtable)
library(dplyr)
```

## Compare hard shell genes vs. accessory


### Short palindromes (k=4, 6)

```{r}
# Pangenome statistics for PTUs
ptu = read.csv('../data/PTU-pangenome-stats.csv')

# Read in RMES comparisons
df_4 = read.csv('~/Downloads/trieste/test_k4.csv')
df_6 = read.csv('~/Downloads/trieste/test_k6.csv')
df_4_filter = df_4[df_4$PTU %in% ptu$PTU[ptu$pangenome.category=="include"],]
df_6_filter = df_6[df_6$PTU %in% ptu$PTU[ptu$pangenome.category=="include"],]
```

Do the statistical test

```{r}
wilcox.test(df_4_filter$discrepancy_selected, df_4_filter$discrepancy_others, paired = TRUE)
wilcox.test(df_6_filter$discrepancy_selected, df_6_filter$discrepancy_others, paired = TRUE)

```
```{r}
ggplot(df_4_filter, aes(x="k=4", wilcoxon_stat, colour=p_value<0.05))+
  geom_point()
```

### All RM targets (not included in main text)

```{r }
df_4 = read.csv('~/Downloads/trieste/test_4mer_targets.csv')
df_4_filter = df_4[df_4$PTU %in% ptu$PTU[ptu$pangenome.category=="include"],]
df_5 = read.csv('~/Downloads/trieste/test_5mer_targets.csv')
df_5_filter = df_5[df_5$PTU %in% ptu$PTU[ptu$pangenome.category=="include"],]
df_6 = read.csv('~/Downloads/trieste/test_6mer_targets.csv')
df_6_filter = df_6[df_6$PTU %in% ptu$PTU[ptu$pangenome.category=="include"],]

wilcox_tests = list(wilcox.test(df_4_filter$discrepancy_selected, df_4_filter$discrepancy_others, paired = TRUE),
                    wilcox.test(df_5_filter$discrepancy_selected, df_5_filter$discrepancy_others, paired = TRUE),
                    wilcox.test(df_6_filter$discrepancy_selected, df_6_filter$discrepancy_others, paired = TRUE))
results_df = data.frame(median_discrepancy_targets=c(median(df_4_filter$discrepancy_selected),
                                        median(df_5_filter$discrepancy_selected),
                                        median(df_6_filter$discrepancy_selected)),
           median_discrepancy_others=c(median(df_4_filter$discrepancy_others),
                                        median(df_5_filter$discrepancy_others),
                                        median(df_6_filter$discrepancy_others)),
           wilcoxon_stat=c(wilcox_tests[[1]]$statistic,
                           wilcox_tests[[2]]$statistic,
                           wilcox_tests[[3]]$statistic),
           p_value=c(wilcox_tests[[1]]$p.value,
                     wilcox_tests[[2]]$p.value,
                     wilcox_tests[[3]]$p.value))
kable(results_df, digits = 3, format = "html")

```

### Hard shell vs. accessory for within-range RM targets

```{r}
# Read in results for RM targets
df_4 = read.csv('../results/rmes_discrepancies_targets_k4.csv')
df_4_filter = df_4[df_4$PTU %in% ptu$PTU[ptu$pangenome.category=="include" & df_4$discrepancy_selected!="None"],]
df_5 = read.csv('../results/rmes_discrepancies_targets_k5.csv')
df_5_filter = df_5[df_5$PTU %in% ptu$PTU[ptu$pangenome.category=="include" & df_5$discrepancy_selected!="None"],]
df_6 = read.csv('../results/rmes_discrepancies_targets_k6.csv')
df_6_filter = df_6[df_6$PTU %in% ptu$PTU[ptu$pangenome.category=="include" & df_6$discrepancy_selected!="None"],]

# Convert discrepancies to numeric (presence of None has messed this up)
df_4_filter$discrepancy_selected = as.numeric(df_4_filter$discrepancy_selected)
df_5_filter$discrepancy_selected = as.numeric(df_5_filter$discrepancy_selected)
df_6_filter$discrepancy_selected = as.numeric(df_6_filter$discrepancy_selected)

wilcox_tests = list(wilcox.test(df_4_filter$discrepancy_selected, df_4_filter$discrepancy_others, paired = TRUE),
                    wilcox.test(df_5_filter$discrepancy_selected, df_5_filter$discrepancy_others, paired = TRUE),
                    wilcox.test(df_6_filter$discrepancy_selected, df_6_filter$discrepancy_others, paired = TRUE))
results_df = data.frame(n_PTUs = c(nrow(df_4_filter),
                                   nrow(df_5_filter),
                                   nrow(df_6_filter)),
                        median_n_targets = c(median(df_4_filter$n_selected_kmers),
                                   median(df_5_filter$n_selected_kmers),
                                   median(df_6_filter$n_selected_kmers)),
  median_discrepancy_targets=c(median(df_4_filter$discrepancy_selected),
                                        median(df_5_filter$discrepancy_selected),
                                        median(df_6_filter$discrepancy_selected)),
           median_discrepancy_others=c(median(df_4_filter$discrepancy_others),
                                        median(df_5_filter$discrepancy_others),
                                        median(df_6_filter$discrepancy_others)),
           wilcoxon_stat=c(wilcox_tests[[1]]$statistic,
                           wilcox_tests[[2]]$statistic,
                           wilcox_tests[[3]]$statistic),
           p_value=c(wilcox_tests[[1]]$p.value,
                     wilcox_tests[[2]]$p.value,
                     wilcox_tests[[3]]$p.value))
kable(results_df, digits = 3, format = "html")
```

## Analysis of leading region

Some preliminary statistics about discarded PTUs (for main text). 

```{r}
lr = read.csv('../data/leading_region_081123.tsv', sep='\t')
plasmid.table = read.csv('../data/plasmid_table.tsv', sep='\t')
retained.PTUs.lr = read.csv('../data/leading-region-PTUs.txt', header=F)$V1
lr.identified.PTU.names = sort(unique(lr$PTU))
# Minimum sizes
PTU.min.sizes = sort(sapply(lr.identified.PTU.names, function(x) 
  min(plasmid.table[plasmid.table$PTU==x, "Size"])))
```

We discard those where the minimum size is <20kb: E1, E3, E9, E10, E14, E76. We check the maximum size per PTU:

```{r}
sort(sapply(paste0("PTU-E", c("1", "3", "9", "10", "14", "76")), function(x) 
  max(plasmid.table[plasmid.table$PTU==x, "Size"])))
```

These PTUs are retained for analysing the leading region:

```{r}
leading.region.PTUs = sort(names(PTU.min.sizes[PTU.min.sizes>20000]))
cat(leading.region.PTUs, sep="\n")
```
### Sliding window analysis

k=6 
```{r}
# Theoretical expectation for 6-bp palindrome density
theoreticalPalindromeExpectation = function(p){# p is GC content
  return ((p**2 - p + 1/2)**3)
}
d = read.csv('../test_output_window5000_step500.csv', header=F, stringsAsFactors = F)
colnames(d) = c("PTU", "plasmid", "x", "window_size", "palindrome_count", "palindrome_density", "GC_n")

d.reduced = d[which(d$PTU %in% leading.region.PTUs), ]

d.reduced$expected_density = theoreticalPalindromeExpectation(d.reduced$GC_n/d.reduced$window_size)

d.reduced$diff_density = d.reduced$palindrome_density-d.reduced$expected_density


# One line per plasmid
d.reduced.median = d.reduced %>% group_by(PTU, x) %>% 
  summarise(median=median(diff_density),
            n=length(diff_density), 
            median.original=median(palindrome_density),
            GC=median(GC_n))

# Maximum counts
d.reduced.median.plot = d.reduced.median %>% 
  group_by(PTU) %>%
  mutate(max_n = max(n, na.rm = TRUE),  # Calculate max 'n' for each 'PTU'
         normalized_n = n / max_n * 100) %>%  # Normalize 'n' by this max value
  ungroup() %>%  # Remove the grouping
  select(-max_n)  # Optionally remove the max_n column if not needed
# Plot the distribution
p.lines.expectation = ggplot(d.reduced.median.plot, aes(x, median*1000))+
  geom_hline(yintercept = 0, linetype='dashed')+
  theme_bw()+
  geom_path(aes(group=PTU, alpha=normalized_n))+
  facet_wrap(~PTU, scales="free_x", nrow=3)+
  ylab("Palindrome depletion per kb (5kb sliding window)")+
  labs(alpha="% of plasmids within PTU")+
  theme(panel.grid=element_blank())+  
  scale_x_continuous(labels = function(x) x / 1000) +
  xlab("Position on plasmid (kb)")+
  theme(legend.position = c(0.8, 0.2))
ggsave(p.lines.expectation, file='../results/6mer-deviation-expectation.pdf',
       width=10, height=6)
# Plot only first 25kb
ggsave(p.lines.expectation+scale_x_continuous(labels = function(x) x / 1000, limits=c(0,50000)), file='../results/6mer-deviation-expectation-0-50-kb.pdf',
       width=10, height=6)

```

### Compare leading region to rest of plasmid

```{r}
# Start from d.reduced, which contains per-plasmid results with 5000bp sliding window and step size of 500bp
# Compare depletion in first 5kb with average for the rest of the plasmid
diff.leading.region.average = d.reduced %>% 
  group_by(plasmid, PTU) %>%
  mutate(diff.count=palindrome_count[x=="0"]-mean(palindrome_count),
         diff.density=diff_density[x=="0"]-mean(diff_density)) %>%
  filter(x=="0")

# Order the PTUs by mean values of depletion for better visual display
mean.values = diff.leading.region.average %>% group_by(PTU) %>%
  summarise(mean=mean(diff.density)*1000)
diff.leading.region.average$PTU = ordered(diff.leading.region.average$PTU,
                                          levels=mean.values$PTU[order(mean.values$mean)])
p.leading.region.diff.density = ggplot(diff.leading.region.average, aes(as.factor(PTU), diff.density*1000))+ # depletion per-kb rather than per-bp
  ggbeeswarm::geom_quasirandom(alpha=0.8)+
  theme_bw()+
  theme(panel.grid = element_blank())+
  geom_hline(yintercept = 0)+
  xlab("")+
  theme(axis.text=element_text(colour="black"))+
  ylab("Palindrome depletion in leading region (per kb)")+
  coord_flip()
p.leading.region.diff.density
# Based on this, remove two outliers
p.leading.region.diff.density = p.leading.region.diff.density+
  ylim(c(-10,5))
ggsave(p.leading.region.diff.density, file='../results/6mer-deviation-leading-region-vs-rest-of-plasmid-density.pdf',
       width=5, height=4)
```



```{r}
library(ggplot2)
library(knitr)
library(xtable)
library(dplyr)
```

## Compare hard shell genes vs. accessory


### Short palindromes (k=4, 6)

```{r}
# Pangenome statistics for PTUs
ptu = read.csv('../data/PTU-pangenome-stats.csv')

# Read in RMES comparisons
df_4 = read.csv('~/Downloads/trieste/test_k4.csv')
df_6 = read.csv('~/Downloads/trieste/test_k6.csv')
df_4_filter = df_4[df_4$PTU %in% ptu$PTU[ptu$pangenome.category=="include"],]
df_6_filter = df_6[df_6$PTU %in% ptu$PTU[ptu$pangenome.category=="include"],]
```

Do the statistical test

```{r}
wilcox.test(df_4_filter$discrepancy_selected, df_4_filter$discrepancy_others, paired = TRUE)
wilcox.test(df_6_filter$discrepancy_selected, df_6_filter$discrepancy_others, paired = TRUE)

```
```{r}
ggplot(df_4_filter, aes(x="k=4", wilcoxon_stat, colour=p_value<0.05))+
  geom_point()
```

### All RM targets (not included in main text)

```{r }
df_4 = read.csv('~/Downloads/trieste/test_4mer_targets.csv')
df_4_filter = df_4[df_4$PTU %in% ptu$PTU[ptu$pangenome.category=="include"],]
df_5 = read.csv('~/Downloads/trieste/test_5mer_targets.csv')
df_5_filter = df_5[df_5$PTU %in% ptu$PTU[ptu$pangenome.category=="include"],]
df_6 = read.csv('~/Downloads/trieste/test_6mer_targets.csv')
df_6_filter = df_6[df_6$PTU %in% ptu$PTU[ptu$pangenome.category=="include"],]

wilcox_tests = list(wilcox.test(df_4_filter$discrepancy_selected, df_4_filter$discrepancy_others, paired = TRUE),
                    wilcox.test(df_5_filter$discrepancy_selected, df_5_filter$discrepancy_others, paired = TRUE),
                    wilcox.test(df_6_filter$discrepancy_selected, df_6_filter$discrepancy_others, paired = TRUE))
results_df = data.frame(median_discrepancy_targets=c(median(df_4_filter$discrepancy_selected),
                                        median(df_5_filter$discrepancy_selected),
                                        median(df_6_filter$discrepancy_selected)),
           median_discrepancy_others=c(median(df_4_filter$discrepancy_others),
                                        median(df_5_filter$discrepancy_others),
                                        median(df_6_filter$discrepancy_others)),
           wilcoxon_stat=c(wilcox_tests[[1]]$statistic,
                           wilcox_tests[[2]]$statistic,
                           wilcox_tests[[3]]$statistic),
           p_value=c(wilcox_tests[[1]]$p.value,
                     wilcox_tests[[2]]$p.value,
                     wilcox_tests[[3]]$p.value))
kable(results_df, digits = 3, format = "html")

```

### Hard shell vs. accessory for within-range RM targets

```{r}
# Read in results for RM targets
df_4 = read.csv('../results/rmes_discrepancies_targets_k4.csv')
df_4_filter = df_4[df_4$PTU %in% ptu$PTU[ptu$pangenome.category=="include" & df_4$discrepancy_selected!="None"],]
df_5 = read.csv('../results/rmes_discrepancies_targets_k5.csv')
df_5_filter = df_5[df_5$PTU %in% ptu$PTU[ptu$pangenome.category=="include" & df_5$discrepancy_selected!="None"],]
df_6 = read.csv('../results/rmes_discrepancies_targets_k6.csv')
df_6_filter = df_6[df_6$PTU %in% ptu$PTU[ptu$pangenome.category=="include" & df_6$discrepancy_selected!="None"],]

# Convert discrepancies to numeric (presence of None has messed this up)
df_4_filter$discrepancy_selected = as.numeric(df_4_filter$discrepancy_selected)
df_5_filter$discrepancy_selected = as.numeric(df_5_filter$discrepancy_selected)
df_6_filter$discrepancy_selected = as.numeric(df_6_filter$discrepancy_selected)

wilcox_tests = list(wilcox.test(df_4_filter$discrepancy_selected, df_4_filter$discrepancy_others, paired = TRUE),
                    wilcox.test(df_5_filter$discrepancy_selected, df_5_filter$discrepancy_others, paired = TRUE),
                    wilcox.test(df_6_filter$discrepancy_selected, df_6_filter$discrepancy_others, paired = TRUE))
results_df = data.frame(n_PTUs = c(nrow(df_4_filter),
                                   nrow(df_5_filter),
                                   nrow(df_6_filter)),
                        median_n_targets = c(median(df_4_filter$n_selected_kmers),
                                   median(df_5_filter$n_selected_kmers),
                                   median(df_6_filter$n_selected_kmers)),
  median_discrepancy_targets=c(median(df_4_filter$discrepancy_selected),
                                        median(df_5_filter$discrepancy_selected),
                                        median(df_6_filter$discrepancy_selected)),
           median_discrepancy_others=c(median(df_4_filter$discrepancy_others),
                                        median(df_5_filter$discrepancy_others),
                                        median(df_6_filter$discrepancy_others)),
           wilcoxon_stat=c(wilcox_tests[[1]]$statistic,
                           wilcox_tests[[2]]$statistic,
                           wilcox_tests[[3]]$statistic),
           p_value=c(wilcox_tests[[1]]$p.value,
                     wilcox_tests[[2]]$p.value,
                     wilcox_tests[[3]]$p.value))
kable(results_df, digits = 3, format = "html")
```

## Analysis of leading region

Some preliminary statistics about discarded PTUs (for main text). 

```{r}
lr = read.csv('../data/leading_region_081123.tsv', sep='\t')
plasmid.table = read.csv('../data/plasmid_table.tsv', sep='\t')
retained.PTUs.lr = read.csv('../data/leading-region-PTUs.txt', header=F)$V1
lr.identified.PTU.names = sort(unique(lr$PTU))
# Minimum sizes
PTU.min.sizes = sort(sapply(lr.identified.PTU.names, function(x) 
  min(plasmid.table[plasmid.table$PTU==x, "Size"])))
```

We discard those where the minimum size is <20kb: E1, E3, E9, E10, E14, E76. We check the maximum size per PTU:

```{r}
sort(sapply(paste0("PTU-E", c("1", "3", "9", "10", "14", "76")), function(x) 
  max(plasmid.table[plasmid.table$PTU==x, "Size"])))
```

These PTUs are retained for analysing the leading region:

```{r}
leading.region.PTUs = sort(names(PTU.min.sizes[PTU.min.sizes>20000]))
cat(leading.region.PTUs, sep="\n")
```
### Sliding window analysis

k=6 
```{r}
# Theoretical expectation for 6-bp palindrome density
theoreticalExpectation = function(p){# p is GC content
  return ((p**2 - p + 1/2)**3)
}
d = read.csv('../test_output.csv', header=F, stringsAsFactors = F)
colnames(d) = c("PTU", "plasmid", "x", "density", "GC_n")

d.reduced = d[which(d$PTU %in% leading.region.PTUs), ]

d.reduced$expected_density_new_calc = theoreticalExpectation(d.reduced$GC_n/5000)

d.reduced$diff_density = d.reduced$density-d.reduced$expected_density_new_calc

medians = d.reduced %>% group_by(PTU, plasmid) %>%
  summarise(median=median(density)) %>% group_by(PTU) %>%
  summarise(median=median(median))


# One line per plasmid
d.reduced.median = d.reduced %>% group_by(PTU, x) %>% 
  summarise(median=median(diff_density),
            n=length(diff_density), 
            median.original=median(density),
            GC=median(GC_n))

# Maximum counts
d.reduced.median.plot = d.reduced.median %>% 
  group_by(PTU) %>%
  mutate(max_n = max(n, na.rm = TRUE),  # Calculate max 'n' for each 'PTU'
         normalized_n = n / max_n * 100) %>%  # Normalize 'n' by this max value
  ungroup() %>%  # Remove the grouping
  select(-max_n)  # Optionally remove the max_n column if not needed
# Plot the distribution
p.lines.expectation = ggplot(d.reduced.median.plot, aes(x, median))+
  geom_hline(yintercept = 0, linetype='dashed')+
  theme_bw()+
  geom_path(aes(group=PTU, alpha=normalized_n))+
  facet_wrap(~PTU, scales="free_x", nrow=3)+
  ylab("Deviation from expected 6-mer palindrome density (5kb sliding window)")+
  labs(alpha="% of plasmids within PTU")+
  theme(panel.grid=element_blank())+  
  scale_x_continuous(labels = function(x) x / 1000) +
  xlab("Position on plasmid (kb)")+
  theme(legend.position = c(0.8, 0.2))
ggsave(p.lines.expectation, file='../results/6mer-deviation-expectation.pdf'.
       width=10, height=8)
```

Repeat for k=4?
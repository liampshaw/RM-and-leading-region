---
title: "Shaw et al. (2025) Supplementary analysis"
author: "Liam Shaw"
output:
  html_document:
    toc: true
---

### Preliminaries 

This script contains analysis and figure generation for Shaw et al. (2025), 'The leading region of many conjugative plasmids is depleted in restriction-modification targets'. For more details, see the associated paper. The code matches the order of appearance of the figures/analysis in the paper and is separated into sections based on the figures. Figure S5 and S6 are not included in this code.

It is intended to be run from inside the `scripts` directory of this repository. Results are saved to to `results` within the repository. 

**Note** This relies on large downloaded files and is not intended to work out-of-the-box. For example, Roary gene presence/absence tables on my computer are stored in `/Users/Liam/Downloads/06_plaspan/`. 

## Dataset 

### Statistics 

First, we load libraries.

```{r, message=FALSE, warning=FALSE}
knitr::opts_chunk$set(warning = FALSE)
library(ggplot2)
library(knitr)
library(xtable)
library(dplyr)
library(tidyr)
```

We calculate some preliminary statistics about the PTUs from our dataset of 50 PTUs that we analyse (see main text). 

```{r}
lr = read.csv('../data/leading_region_081123.tsv', sep='\t')
plasmid.table = read.csv('../data/plasmid_table.tsv', sep='\t')
retained.PTUs.lr = read.csv('../data/leading-region-PTUs.txt', header=F)$V1
lr.identified.PTU.names = sort(unique(lr$PTU))
# Minimum sizes
PTU.min.sizes = sort(sapply(lr.identified.PTU.names, function(x) 
  min(plasmid.table[plasmid.table$PTU==x, "Size"])))
```

We discard those where the minimum size of plasmids in the PTU is <20kb: E1, E3, E9, E10, E14, E76. We check the maximum size per PTU:

```{r}
sort(sapply(paste0("PTU-E", c("1", "3", "9", "10", "14", "76")), function(x) 
  max(plasmid.table[plasmid.table$PTU==x, "Size"])))
```

These PTUs are retained for analysing the leading region:

```{r}
leading.region.PTUs = sort(names(PTU.min.sizes[PTU.min.sizes>20000]))
cat(leading.region.PTUs, sep="\n")
```

For convenience for other scripts, we save some files with names of plasmids within each PTU.

```{r}
for (PTU in unique(plasmid.table$PTU)){
  cat(plasmid.table$ID[plasmid.table$PTU==PTU], sep="\n",
      file=paste0('~/Downloads/trieste/', PTU, '_plasmids.txt'))
}

```

### Figure 1

Figure 1. Summary of the 36 plasmid taxonomic units (PTUs) analysed in this paper. 

```{r, message=FALSE}
ptu = read.csv('../data/PTU-pangenome-stats.csv')
for (each_ptu in ptu$PTU){
  gene_pa_file <- list.files(paste0("/Users/Liam/Downloads/06_plaspan/", each_ptu), 
                        pattern = "gene_presence_absence.Rtab$", full.names = TRUE, recursive = TRUE)
  gene_counts = read.csv(gene_pa_file, sep='\t', row.names = 1)
  ptu$median.genes[which(ptu$PTU==each_ptu)] = median(colSums(gene_counts))
  ptu$max.genes[which(ptu$PTU==each_ptu)] = max(colSums(gene_counts))
  ptu$min.genes[which(ptu$PTU==each_ptu)] = min(colSums(gene_counts))
}

# Set up for plotting
ptu_for_plotting = ptu %>% pivot_longer(cols=c("n.core", "n.others"))
# Order by median size (no. of genes)
ptu = ptu[order(ptu$median.genes),]
ptu$PTU = ordered(ptu$PTU, 
                  levels=rev(ptu$PTU))
ptu$leading.region = ifelse(ptu$PTU %in% leading.region.PTUs,
                            "yes", "no")
# Make the figure
pdf('../results/Figure-1-ptu-summary-pangenome-plot.pdf', width=9, height=5)
p.figure1 = ggplot(ptu[which(ptu$median.genes>20),], aes(PTU, median.genes, ymin=min.genes, ymax=max.genes,
                                             fill=leading.region))+
  geom_bar(aes(y=n.core), stat="identity")+
  geom_errorbar()+
  geom_point(shape=21)+
  theme_bw()+
  xlab("")+
  ylab("Number of genes")+
  labs(fill="Leading region analysed")+
  coord_flip()+
  scale_color_brewer(palette="Set2")+
  scale_fill_brewer(palette="Set2")+
  theme(axis.text=element_text(colour="black"))
p.figure1
dev.off()
p.figure1
```

## Sliding window analysis

### Figures S1-S3

We plot results of sliding window analysis over the conjugative plasmids for k=6. This produces Figure 

```{r, message=FALSE}
# Theoretical expectation for 6-bp palindrome density
theoreticalPalindromeExpectation = function(p){# p is GC content
  return ((p**2 - p + 1/2)**3)
}
d = read.csv('../test_output_window5000_step500.csv', header=F, stringsAsFactors = F)
colnames(d) = c("PTU", "plasmid", "x", "window_size", "palindrome_count", "palindrome_density", "GC_n")

d.reduced = d[which(d$PTU %in% leading.region.PTUs), ]

d.reduced$expected_density = theoreticalPalindromeExpectation(d.reduced$GC_n/d.reduced$window_size)

d.reduced$diff_density = d.reduced$palindrome_density-d.reduced$expected_density

# One line per plasmid
d.reduced.median = d.reduced %>% group_by(PTU, x) %>% 
  summarise(median=median(diff_density),
            n=length(diff_density), 
            median.original=median(palindrome_density),
            GC=median(GC_n))
# Maximum counts
d.reduced.median.plot = d.reduced.median %>% 
  group_by(PTU) %>%
  mutate(max_n = max(n, na.rm = TRUE),  # Calculate max 'n' for each 'PTU'
         normalized_n = n / max_n * 100) %>%  # Normalize 'n' by this max value
  ungroup() %>%  # Remove the grouping
  select(-max_n)  # Optionally remove the max_n column if not needed

# Sliding window for GC content, S1
p.figureS1 = ggplot(d.reduced.median.plot, aes(x, GC/5000 * 100))+
  geom_hline(yintercept = 0, linetype='dashed')+
  theme_bw()+
  geom_path(aes(group=PTU, alpha=normalized_n))+
  facet_wrap(~PTU, scales="free_x", nrow=3)+
  ylab("GC content (5kb sliding window)")+
  labs(alpha="% of plasmids within PTU")+
  theme(panel.grid=element_blank())+  
  scale_x_continuous(labels = function(x) x / 1000) +
  xlab("Position on plasmid (kb)")+
  theme(legend.position = c(0.8, 0.2))
ggsave(p.figureS1, file='../results/Figure-S1-GC-content.pdf',
       width=10, height=6)
p.figureS1

overall.median.GC = d.reduced %>% filter(x<50000) %>%
  group_by(x) %>%
  summarise(y=mean(GC_n),
            n=length(GC_n))
p.figureS1.overall = ggplot(overall.median.GC, aes(x, y/5000 * 100))+
  geom_line()+
  theme_bw()+
  theme(panel.grid = element_blank())+
  geom_hline(yintercept = 50, linetype='dashed')+
  ylab("GC content (per kb)")+
    scale_x_continuous(labels = function(x) x / 1000) +
  xlab("Position on plasmid (kb)")+
  theme(axis.text=element_text(colour="black"))
p.figureS1.overall
# Save
ggsave(p.figureS1.overall, file='../results/Figure-S1-GC-mean-overall.pdf', 
       width=5, height=2)

# Plot the distribution, S2
p.figureS2 = ggplot(d.reduced.median.plot, aes(x, median*1000))+
  geom_hline(yintercept = 0, linetype='dashed')+
  theme_bw()+
  geom_path(aes(group=PTU, alpha=normalized_n))+
  facet_wrap(~PTU, scales="free_x", nrow=3)+
  ylab("Palindrome depletion per kb (5kb sliding window)")+
  labs(alpha="% of plasmids within PTU")+
  theme(panel.grid=element_blank())+  
  scale_x_continuous(labels = function(x) x / 1000) +
  xlab("Position on plasmid (kb)")+
  theme(legend.position = c(0.8, 0.2))
ggsave(p.figureS2, file='../results/Figure-S2-6mer-deviation-expectation.pdf',
       width=10, height=6)
p.figureS2
```

```{r}
# And for palindrome density (not expected - actual values)
p.figureS3 = ggplot(d.reduced.median.plot, aes(x, median.original*1000))+
  geom_hline(yintercept = 0, linetype='dashed')+
  theme_bw()+
  geom_path(aes(group=PTU, alpha=normalized_n))+
  facet_wrap(~PTU, scales="free_x", nrow=3)+
  ylab("Palindrome density per kb (5kb sliding window)")+
  labs(alpha="% of plasmids within PTU")+
  theme(panel.grid=element_blank())+  
  scale_x_continuous(labels = function(x) x / 1000) +
  xlab("Position on plasmid (kb)")+
  theme(legend.position = c(0.8, 0.2))
ggsave(p.figureS3, file='../results/Figure-S3-6mer-palindrome-density.pdf',
       width=10, height=6)
p.figureS3
```

### Figure 2

Figure 2. RM target depletion in the leading region of conjugative plasmids. 

```{r}
overall.median = d.reduced %>% filter(x<50000) %>%
  group_by(x) %>%
  summarise(y=median(diff_density),
            n=length(diff_density))
p.overall.average = ggplot(overall.median, aes(x, y*1000))+
  geom_line()+
  scale_y_continuous(breaks=seq(-10, 0, 2), limits = c(-9, 0))+
  theme_bw()+
  theme(panel.grid = element_blank())+
  geom_hline(yintercept = 0, linetype='dashed')+
  ylab("Palindrome depletion (per kb)")+
    scale_x_continuous(labels = function(x) x / 1000) +
  xlab("Position on plasmid (kb)")+
  theme(axis.text=element_text(colour="black"))
p.overall.average
# Save
ggsave(p.overall.average, file='../results/Figure-2-6mer-deviation-overall.pdf', 
       width=3, height=3)
```

This is the main panel of the figure.

```{r}
# Start from d.reduced, which contains per-plasmid results with 5000bp sliding window and step size of 500bp
# Compare depletion in first 5kb with average for the rest of the plasmid
diff.leading.region.average = d.reduced %>% 
  group_by(plasmid, PTU) %>%
  mutate(diff.count=palindrome_count[x=="0"]-mean(palindrome_count),
         diff.density=diff_density[x=="0"]-mean(diff_density),
         diff.GC=(GC_n[x=="0"]-mean(GC_n))/5000 * 100) %>%
  filter(x=="0")

# Order the PTUs by mean values of depletion for better visual display
mean.values = diff.leading.region.average %>% group_by(PTU) %>%
  summarise(mean=mean(diff.density)*1000)
diff.leading.region.average$PTU = ordered(gsub("PTU-", "", diff.leading.region.average$PTU),
                                          levels=gsub("PTU-", "", mean.values$PTU[order(mean.values$mean)]))
p.leading.region.diff.density = ggplot(diff.leading.region.average, aes(as.factor(PTU), diff.density*1000))+ # depletion per-kb rather than per-bp
  ggbeeswarm::geom_quasirandom(alpha=0.8)+
  theme_bw()+
  theme(panel.grid = element_blank())+
  geom_hline(yintercept = 0)+
  xlab("")+
  theme(axis.text=element_text(colour="black", size=18))+
  ylab("Palindrome depletion in leading region (per kb)")+
  theme(axis.text.x=element_text(angle=45, hjust=1))+
  ylab("")
p.leading.region.diff.density
# Based on this, remove two outliers
p.leading.region.diff.density = p.leading.region.diff.density+
  scale_y_continuous(breaks=seq(-8, 4, 2), limits=c(-8,5))
ggsave(p.leading.region.diff.density, file='../results/Figure-2-6mer-deviation-leading-region-vs-rest-of-plasmid-density.pdf',
       width=5.5, height=6)
```

This is the inset panel which is added into the panel above to create the figure in the paper.


### Figure 3

Figure 3. GC-rich leading regions are more depleted in 6-bp palindromes. Values are calculated for the 5-10kb section of the leading region relative to the mean average value over the whole length of the plasmid. Spearman’s correlations are given as inset values. The relationship between relative GC content and palindrome depletion was still significant in a linear model controlling for PTU (depletion ~ GC*PTU). 

```{r}
diff.PTU.averages = diff.leading.region.average %>% group_by(PTU) %>%
  summarise(mean.GC=mean(diff.GC),
            GC=mean(GC_n[x=="0"]/5000 * 100),
            mean.palindrome=mean(palindrome_density),
            mean.palindrome.diff=mean(diff.density) * 1000,
            n=length(diff.GC))

# Calculate actual GC and actual palindrome density
# for a given x-value. 5kb is appropriate for leading region to 
# get the strongest signal (see Figure 2). 
gc_data_frame = function(position_on_plasmid){
  d.reduced %>% 
  group_by(plasmid, PTU) %>%
  mutate(GC=GC_n[x==position_on_plasmid]/5000 * 100,
         diff.GC=(GC_n[x==position_on_plasmid]-mean(GC_n))/5000 * 100,
         density=palindrome_density[x==position_on_plasmid]*1000,
         density.depletion=diff_density[x==position_on_plasmid]*1000) %>%
  filter(x==position_on_plasmid)
}
d.GC.palindrome = gc_data_frame(5000)

d.GC.palindrome.PTU = d.GC.palindrome %>% group_by(PTU) %>%
  summarise(GC=mean(GC),
            diff.GC=mean(diff.GC),
            density=mean(density),
            density.depletion=mean(density.depletion),
            n=length(window_size))

p.figure3a = ggplot(d.GC.palindrome, aes(diff.GC, density.depletion))+
  geom_point()+
  theme_bw()+
  xlab("Relative GC content at 5-10kb (%)")+
  ylab("Relative palindrome depletion at 5-10kb (per kb)")+
    xlim(c(-15, 10))+
  ylim(-13, 14)
p.figure3b =  ggplot(d.GC.palindrome.PTU, aes(diff.GC, density.depletion))+
  geom_point(aes(size=n, fill=PTU), shape=21, colour="black")+
  theme_bw()+
  ggrepel::geom_text_repel(aes(label=PTU), size=2, min.segment.length = 0)+
  guides(fill=FALSE)+
    xlab("Relative GC content (%)")+
  ylab("Relative palindrome depletion (per kb)")
pdf('../results/Figure-3-GC-correlation-depletion.pdf', width=8, height=4)
p.figure3 = cowplot::plot_grid(p.figure3a+ggtitle("(a)"), p.figure3b+ggtitle("(b)"))
p.figure3
dev.off()
p.figure3
# Calculate correlations
cor.test(d.GC.palindrome$diff.GC, d.GC.palindrome$density.depletion, method="spearman")
cor.test(d.GC.palindrome.PTU$diff.GC, d.GC.palindrome.PTU$density.depletion)
```

## Depletion of specific targets

### Figure 4

Figure 4: Average depletion of within-range RM targets in the leading vs. lagging regions for conjugative PTUs. 

```{r}

results = NULL
for (PTU in leading.region.PTUs){
  for (k in c(5,6)){
    scores_df = read.csv(paste0('../test_target_leading_lagging/', PTU, '_k', k, '_scores.csv'), header=T)
    n_targets = nrow(scores_df)
    scores_average <- scores_df %>%
  rowwise() %>%
  mutate(score_avg = mean(c_across(starts_with("score")))) %>%
  ungroup() %>%
  select(kmer, score_avg)
    counts_df = read.csv(paste0('../test_target_leading_lagging/', PTU, '_k', k, '_counts.csv'), header=T)
    counts_average <- counts_df %>%
  rowwise() %>%
  mutate(count_avg = mean(c_across(starts_with("count")))) %>%
  ungroup() %>%
  select(kmer, count_avg)
    results = rbind(results, c(PTU, k, n_targets, median(scores_average$score_avg), median(counts_average$count_avg)))
  }
}

results = data.frame(results)
colnames(results) = c("PTU", "k", "n.targets", "median.score", "median.count")
results$median.score= as.numeric(results$median.score)
results$median.count = as.numeric(results$median.count)

# Order by median score for k=6
order.k.6.scores = results[which(results$k==6), "PTU"][order(results[which(results$k==6), "median.score"])]
results$PTU = ordered(results$PTU,
                      levels=rev(order.k.6.scores))

p.figure4 = ggplot(results, aes(median.score, as.factor(PTU)))+
  geom_vline(xintercept = 0, size=1)+
  geom_bar(stat="identity", position="dodge")+
  facet_wrap(~k, scales="free_x")+
  ylab("")+
  xlab("Median depletion score of within-range RM targets\n(leading vs. lagging, 10kb)")+
   theme_bw()+
  theme(panel.grid = element_blank())+
  theme(axis.text=element_text(colour="black", size=12),
        axis.title.x=element_text(size=24),
        axis.text.x=element_text(size=18))+
  theme(axis.text.y=element_text(hjust=0))
ggsave(p.figure4, file='../results/Figure-4-figure-depletion-within-range-targets.pdf',
       width=10, height=6)
```


### Figure S4

```{r}
scores_df = read.csv('../test_6mer_leading_lagging_scores.csv', header=T)
scores_average <- scores_df %>%
  rowwise() %>%
  mutate(score_avg = mean(c_across(starts_with("score")))) %>%
  ungroup() %>%
  select(kmer, score_avg)  
# Order by average score
scores_average$kmer = ordered(scores_average$kmer,
                              levels=scores_average$kmer[order(scores_average$score_avg)])
scores.plot = ggplot(scores_average, aes(kmer, score_avg))+geom_point()+
  coord_flip()

# Same for counts
counts_df = read.csv('../test_6mer_leading_lagging_counts.csv', header=T)
counts_average <- counts_df %>%
  rowwise() %>%
  mutate(count_avg = mean(c_across(starts_with("count")))) %>%
  ungroup() %>%
  select(kmer, count_avg)  

# Merge together
merge_scores_counts = merge(counts_average, scores_average, by="kmer")
# average score and average count are well-correlated
ggplot(merge_scores_counts, aes(count_avg, score_avg))+geom_point()

# Order by average score
merge_scores_counts$kmer = ordered(merge_scores_counts$kmer,
                              levels=scores_average$kmer[order(scores_average$score_avg)])
p.figureS4 = ggplot(merge_scores_counts, aes(score_avg, kmer))+
    geom_vline(xintercept = 0)+
  geom_bar(stat="identity")+
  geom_vline(xintercept = median(merge_scores_counts$score_avg), linetype='dashed', colour='red')+
  theme_bw()+
  theme(axis.text=element_text(colour="black", size=12),
        axis.title.x=element_text(size=24),
        axis.text.x=element_text(size=18))+
  theme(axis.text.y=element_text(hjust=0))+
  ylab("")+
  xlab("Mean depletion score\n(leading vs. lagging, 10kb)")
wilcox.test(merge_scores_counts$score_avg)
ggsave(p.figureS4, file='../results/Figure-S4-6mer-palindromes-scores.pdf',
       height=10, width=10)
```

## Other analysis

For more details on the analysis below, see Supplementary Text 1.

### Short palindromes (k=4, 6)

```{r}
# Pangenome statistics for PTUs
#ptu = read.csv('../data/PTU-pangenome-stats.csv')

# Read in RMES comparisons
df_4 = read.csv('~/Downloads/trieste/test_k4.csv')
df_6 = read.csv('~/Downloads/trieste/test_k6.csv')
df_4_filter = df_4[df_4$PTU %in% ptu$PTU[ptu$pangenome.category=="include"],]
df_6_filter = df_6[df_6$PTU %in% ptu$PTU[ptu$pangenome.category=="include"],]
```

Do the statistical test

```{r}
wilcox.test(df_4_filter$discrepancy_selected, df_4_filter$discrepancy_others, paired = TRUE)
wilcox.test(df_6_filter$discrepancy_selected, df_6_filter$discrepancy_others, paired = TRUE)

```

### All RM targets (not included in main text)

```{r }
df_4 = read.csv('~/Downloads/trieste/test_4mer_targets.csv')
df_4_filter = df_4[df_4$PTU %in% ptu$PTU[ptu$pangenome.category=="include"],]
df_5 = read.csv('~/Downloads/trieste/test_5mer_targets.csv')
df_5_filter = df_5[df_5$PTU %in% ptu$PTU[ptu$pangenome.category=="include"],]
df_6 = read.csv('~/Downloads/trieste/test_6mer_targets.csv')
df_6_filter = df_6[df_6$PTU %in% ptu$PTU[ptu$pangenome.category=="include"],]

wilcox_tests = list(wilcox.test(df_4_filter$discrepancy_selected, df_4_filter$discrepancy_others, paired = TRUE),
                    wilcox.test(df_5_filter$discrepancy_selected, df_5_filter$discrepancy_others, paired = TRUE),
                    wilcox.test(df_6_filter$discrepancy_selected, df_6_filter$discrepancy_others, paired = TRUE))
results_df = data.frame(median_discrepancy_targets=c(median(df_4_filter$discrepancy_selected),
                                        median(df_5_filter$discrepancy_selected),
                                        median(df_6_filter$discrepancy_selected)),
           median_discrepancy_others=c(median(df_4_filter$discrepancy_others),
                                        median(df_5_filter$discrepancy_others),
                                        median(df_6_filter$discrepancy_others)),
           wilcoxon_stat=c(wilcox_tests[[1]]$statistic,
                           wilcox_tests[[2]]$statistic,
                           wilcox_tests[[3]]$statistic),
           p_value=c(wilcox_tests[[1]]$p.value,
                     wilcox_tests[[2]]$p.value,
                     wilcox_tests[[3]]$p.value))
kable(results_df, digits = 3, format = "html")

```

### Hard shell vs. accessory for within-range RM targets

```{r}
# Read in results for RM targets
df_4 = read.csv('../results/rmes_discrepancies_targets_k4.csv')
df_4_filter = df_4[df_4$PTU %in% ptu$PTU[ptu$pangenome.category=="include" & df_4$discrepancy_selected!="None"],]
df_5 = read.csv('../results/rmes_discrepancies_targets_k5.csv')
df_5_filter = df_5[df_5$PTU %in% ptu$PTU[ptu$pangenome.category=="include" & df_5$discrepancy_selected!="None"],]
df_6 = read.csv('../results/rmes_discrepancies_targets_k6.csv')
df_6_filter = df_6[df_6$PTU %in% ptu$PTU[ptu$pangenome.category=="include" & df_6$discrepancy_selected!="None"],]

# Convert discrepancies to numeric (presence of None has messed this up)
df_4_filter$discrepancy_selected = as.numeric(df_4_filter$discrepancy_selected)
df_5_filter$discrepancy_selected = as.numeric(df_5_filter$discrepancy_selected)
df_6_filter$discrepancy_selected = as.numeric(df_6_filter$discrepancy_selected)

wilcox_tests = list(wilcox.test(df_4_filter$discrepancy_selected, df_4_filter$discrepancy_others, paired = TRUE),
                    wilcox.test(df_5_filter$discrepancy_selected, df_5_filter$discrepancy_others, paired = TRUE),
                    wilcox.test(df_6_filter$discrepancy_selected, df_6_filter$discrepancy_others, paired = TRUE))
results_df = data.frame(n_PTUs = c(nrow(df_4_filter),
                                   nrow(df_5_filter),
                                   nrow(df_6_filter)),
                        median_n_targets = c(median(df_4_filter$n_selected_kmers),
                                   median(df_5_filter$n_selected_kmers),
                                   median(df_6_filter$n_selected_kmers)),
  median_discrepancy_targets=c(median(df_4_filter$discrepancy_selected),
                                        median(df_5_filter$discrepancy_selected),
                                        median(df_6_filter$discrepancy_selected)),
           median_discrepancy_others=c(median(df_4_filter$discrepancy_others),
                                        median(df_5_filter$discrepancy_others),
                                        median(df_6_filter$discrepancy_others)),
           wilcoxon_stat=c(wilcox_tests[[1]]$statistic,
                           wilcox_tests[[2]]$statistic,
                           wilcox_tests[[3]]$statistic),
           p_value=c(wilcox_tests[[1]]$p.value,
                     wilcox_tests[[2]]$p.value,
                     wilcox_tests[[3]]$p.value))
kable(results_df, digits = 3, format = "html")
```

We repeat this analysis with one gene representative per family:

```{r}
# Read in results for RM targets
df_4 = read.csv('../test_one_per_family_within_range_targets_k4.csv')
df_5 = read.csv('../test_one_per_family_within_range_targets_k5.csv')
df_6 = read.csv('../test_one_per_family_within_range_targets_k6.csv')

# Convert discrepancies to numeric (presence of None has messed this up)
df_4$discrepancy_selected = as.numeric(df_4$discrepancy_selected)
df_4$discrepancy_selected[is.na(df_4$discrepancy_selected)] = 0
df_5$discrepancy_selected = as.numeric(df_5$discrepancy_selected)
df_5$discrepancy_selected[is.na(df_5$discrepancy_selected)] = 0
df_6$discrepancy_selected = as.numeric(df_6$discrepancy_selected)
df_6$discrepancy_selected[is.na(df_6$discrepancy_selected)] = 0

# Median of selected k-mers
df = t(data.frame(c(median(df_4[which(df_4$n_selected_kmers!=0),"discrepancy_selected"]), 
        wilcox.test(df_4[which(df_4$n_selected_kmers!=0),"discrepancy_selected"])$statistic,
        wilcox.test(df_4[which(df_4$n_selected_kmers!=0),"discrepancy_selected"])$p.value),
        c(median(df_5[which(df_5$n_selected_kmers!=0),"discrepancy_selected"]), 
        wilcox.test(df_5[which(df_5$n_selected_kmers!=0),"discrepancy_selected"])$statistic,
        wilcox.test(df_5[which(df_5$n_selected_kmers!=0),"discrepancy_selected"])$p.value),
        c(median(df_6[which(df_6$n_selected_kmers!=0),"discrepancy_selected"]), 
        wilcox.test(df_6[which(df_6$n_selected_kmers!=0),"discrepancy_selected"])$statistic,
        wilcox.test(df_6[which(df_6$n_selected_kmers!=0),"discrepancy_selected"])$p.value)))
colnames(df) = c("median", "statistic", "p.value")
print(df)
```

We then subsample to one representative per gene family and the same number of hard shell and accessory genes, whichever is smaller (PTU-Bac37 is the only PTU that had more hard shell than accessory genes). 

```{r}
palindromes_k4 = tolower(read.csv('~/Downloads/trieste/k4.txt', header=F)$V1)
palindromes_k6 = tolower(read.csv('~/Downloads/trieste/k6.txt', header=F)$V1)

core_k6 = read.csv('~/Downloads/trieste/one_per_family/all_core_1745k_k6.csv')
accessory_k6 = read.csv('~/Downloads/trieste/one_per_family/all_accessory_1745k_k6.csv')
merge_k6 = merge(core_k6, accessory_k6, by="word")
merge_k6$score.diff = merge_k6$score.x-merge_k6$score.y
merge_k6$count.diff = merge_k6$count.x-merge_k6$count.y

merge_k6$palindrome = ifelse(merge_k6$word %in% palindromes_k6,
                             "palindrome", "other")
median(merge_k6[which(merge_k6$palindrome=="palindrome"),"score.diff"])
wilcox.test(merge_k6[which(merge_k6$palindrome=="palindrome"),"score.diff"])
sum(merge_k6$count.x[which(merge_k6$palindrome=="palindrome")])/sum(merge_k6$count.x) * 1000
sum(merge_k6$count.y[which(merge_k6$palindrome=="palindrome")])/sum(merge_k6$count.y) * 1000

# And for k=4

core_k4 = read.csv('~/Downloads/trieste/one_per_family/all_core_1745k_k4.csv')
accessory_k4 = read.csv('~/Downloads/trieste/one_per_family/all_accessory_1745k_k4.csv')
merge_k4 = merge(core_k4, accessory_k4, by="word")
merge_k4$score.diff = merge_k4$score.x-merge_k4$score.y
merge_k4$count.diff = merge_k4$count.x-merge_k4$count.y

merge_k4$palindrome = ifelse(merge_k4$word %in% palindromes_k4,
                             "palindrome", "other")
median(merge_k4[which(merge_k4$palindrome=="palindrome"),"score.diff"])
wilcox.test(merge_k4[which(merge_k4$palindrome=="palindrome"),"score.diff"])

# Sum palindromes
sum(merge_k4$count.x[which(merge_k4$palindrome=="palindrome")])/sum(merge_k4$count.x) * 1000
sum(merge_k4$count.y[which(merge_k4$palindrome=="palindrome")])/sum(merge_k4$count.y) * 1000

```


### All motifs testing for over-representation

Go through values of k for across PTU averages. 

```{r}
# Normalise
PTU.counts = table(plasmid.table$PTU)
n.plasmids = PTU.counts[leading.region.PTUs]
# k= 4
# 6-bp palindromes
palindromes = read.csv('~/Downloads/trieste/k4.txt', header=F)$V1
results.df = read.csv('../test_ptus_k4_scores.csv',header=T)
# Add PTUs as column names
colnames(results.df)[2:ncol(results.df)] = leading.region.PTUs
results.df.norm = results.df %>%
mutate(across(starts_with("PTU-"), ~ .x / n.plasmids[cur_column()], .names = "{.col}"))
# Plot all palindromes
results.df.long = results.df.norm %>%
pivot_longer(cols = starts_with("PTU"),
names_to = "score_type",
values_to = "score_avg")
results.df.norm.average = results.df.long %>% group_by(kmer) %>%
summarise(median=median(score_avg)) %>%
arrange(median)
# Take the top 1% depleted
results.df.norm.average.top.depleted = results.df.norm.average[which(results.df.norm.average$median< quantile(results.df.norm.average$median, probs = c(0.05))),] # not enough for 0.01
results.df.norm.average.top.depleted$palindrome = ifelse(results.df.norm.average.top.depleted$kmer %in% palindromes,
"palindrome",
"non-palindrome")
# Read in all RM targets
all_rm_targets = read.csv('../data/rebase_all_4_6bp_targets_250131.csv', header=T)
all_rm_targets_4bp =all_rm_targets$target[all_rm_targets$length==4]
results.df.norm.average.top.depleted$target = ifelse(results.df.norm.average.top.depleted$kmer %in%
all_rm_targets_4bp,
"target", "non-target")
table(results.df.norm.average.top.depleted$palindrome)
table(results.df.norm.average.top.depleted$target)
# palindromes
chisq.test(matrix(c(2, 11, 13, 230 ), nrow=2))
# Targets
chisq.test(matrix(c(3, 10, 100, 143 ), nrow=2))


### And for k=5
results.df = read.csv('../test_ptus_k5_scores.csv',header=T)
# Add PTUs as column names
colnames(results.df)[2:ncol(results.df)] = leading.region.PTUs
results.df.norm = results.df %>%
mutate(across(starts_with("PTU-"), ~ .x / n.plasmids[cur_column()], .names = "{.col}"))
results.df.long = results.df.norm %>%
pivot_longer(cols = starts_with("PTU"),
names_to = "score_type",
values_to = "score_avg")
results.df.norm.average = results.df.long %>% group_by(kmer) %>%
summarise(median=median(score_avg)) %>%
arrange(median)
# Take the top 1% depleted
results.df.norm.average.top.depleted = results.df.norm.average[which(results.df.norm.average$median< quantile(results.df.norm.average$median, probs = c(0.01))),] 
all_rm_targets_5bp =all_rm_targets$target[all_rm_targets$length==5]
results.df.norm.average.top.depleted$target = ifelse(results.df.norm.average.top.depleted$kmer %in%
all_rm_targets_5bp,
"target", "non-target")
table(results.df.norm.average.top.depleted$target)
chisq.test(matrix(c(5, 11, 277, 731 ), nrow=2))


# k =6
# 6-bp palindromes
palindromes = read.csv('~/Downloads/trieste/k6.txt', header=F)$V1
results.df = read.csv('../test_ptus_k6_scores.csv',header=T)
# Add PTUs as column names
colnames(results.df)[2:ncol(results.df)] = leading.region.PTUs
results.df.norm = results.df %>%
mutate(across(starts_with("PTU-"), ~ .x / n.plasmids[cur_column()], .names = "{.col}"))
# Switch to long format
results.df.long = results.df.norm %>%
pivot_longer(cols = starts_with("PTU"),
names_to = "score_type",
values_to = "score_avg")

results.df.norm.average = results.df.long %>% group_by(kmer) %>%
summarise(median=median(score_avg)) %>%
arrange(median)
# Take the top 1% depleted
results.df.norm.average.top.depleted = results.df.norm.average[which(results.df.norm.average$median< quantile(results.df.norm.average$median, probs = c(0.01))),]
results.df.norm.average.top.depleted$palindrome = ifelse(results.df.norm.average.top.depleted$kmer %in% palindromes,
"palindrome",
"non-palindrome")
# Read in all RM targets
all_rm_targets = read.csv('../data/rebase_all_4_6bp_targets_250131.csv', header=F, sep=' ')
all_rm_targets_6bp =all_rm_targets$target[all_rm_targets$length==6]
results.df.norm.average.top.depleted$target = ifelse(results.df.norm.average.top.depleted$kmer %in%
all_rm_targets_6bp,
"target", "non-target")
table(results.df.norm.average.top.depleted$palindrome)
table(results.df.norm.average.top.depleted$target)
chisq.test(matrix(c(7, 34, 865-7, 4096-865-34 ), nrow=2))
chisq.test(matrix(c(4, 37, 60, 4055 ), nrow=2))
```
